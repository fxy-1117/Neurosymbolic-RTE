{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e5f3c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk,re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from amr_logic_converter import types\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from word_forms.word_forms import get_word_forms\n",
    "from sympy.logic.boolalg import to_cnf\n",
    "from sympy.abc import A, B,C\n",
    "import sympy\n",
    "from sklearn.metrics import classification_report\n",
    "from sympy import Symbol,simplify_logic\n",
    "from pysat.formula import CNF\n",
    "from pysat.solvers import Solver\n",
    "from pattern.en import conjugate, lemma, lexeme, PRESENT, SG\n",
    "import inflect\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dce7057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from cache /Users/xuyaofeng/.cache/torch/DATA/amr3joint_ontowiki2_g2g/models/amr3joint_ontowiki2_g2g-structured-bart-large/seed43/checkpoint_wiki.smatch_top5-avg.pt\n",
      "| [en] dictionary: 157880 types\n",
      "| [actions_nopos] dictionary: 58901 types\n",
      "----------loading pretrained bart.large model ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/xuyaofeng/.cache/torch/hub/pytorch_fairseq_main\n",
      "2024-04-27 16:33:07 | INFO | fairseq.file_utils | loading archive file http://dl.fbaipublicfiles.com/fairseq/models/bart.large.tar.gz from cache at /Users/xuyaofeng/.cache/torch/pytorch_fairseq/40858f8de84f479771b2807266d806749e9ad0f8cb547921c35a76ae9c3ed0f6.099ef973524a5edb31b1211569b67bcc2863bc6d00781b79bac752acf8e48991\n",
      "2024-04-27 16:33:09 | INFO | fairseq.tasks.denoising | dictionary: 50264 types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- task bart rewind: loading pretrained bart.large model ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/xuyaofeng/.cache/torch/hub/pytorch_fairseq_main\n",
      "2024-04-27 16:33:19 | INFO | fairseq.file_utils | loading archive file http://dl.fbaipublicfiles.com/fairseq/models/bart.large.tar.gz from cache at /Users/xuyaofeng/.cache/torch/pytorch_fairseq/40858f8de84f479771b2807266d806749e9ad0f8cb547921c35a76ae9c3ed0f6.099ef973524a5edb31b1211569b67bcc2863bc6d00781b79bac752acf8e48991\n",
      "2024-04-27 16:33:20 | INFO | fairseq.tasks.denoising | dictionary: 50264 types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CPU for models\n",
      "pretrained_embed:  bart.large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/xuyaofeng/.cache/torch/hub/pytorch_fairseq_main\n",
      "2024-04-27 16:33:41 | INFO | fairseq.file_utils | loading archive file http://dl.fbaipublicfiles.com/fairseq/models/bart.large.tar.gz from cache at /Users/xuyaofeng/.cache/torch/pytorch_fairseq/40858f8de84f479771b2807266d806749e9ad0f8cb547921c35a76ae9c3ed0f6.099ef973524a5edb31b1211569b67bcc2863bc6d00781b79bac752acf8e48991\n",
      "2024-04-27 16:33:42 | INFO | fairseq.tasks.denoising | dictionary: 50264 types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bart.large extraction in cpu (slow, wont OOM)\n",
      "Finished loading models\n",
      "self.machine_config:  /Users/xuyaofeng/.cache/torch/DATA/amr3joint_ontowiki2_g2g/models/amr3joint_ontowiki2_g2g-structured-bart-large/seed43/machine_config.json\n"
     ]
    }
   ],
   "source": [
    "from transition_amr_parser.parse import AMRParser\n",
    "from amr_logic_converter import AmrLogicConverter\n",
    "from transformers import pipeline\n",
    "# Download and save a model named AMR3.0 to cache\n",
    "parser = AMRParser.from_pretrained('AMR3-joint-ontowiki-seed43')\n",
    "# tokens, positions = parser.tokenize('church-goers group sentences')\n",
    "converter = AmrLogicConverter(existentially_quantify_instances=False,invert_relations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "620e9a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 16:33:53 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "2024-04-27 16:33:54 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b3d9b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_logic(data):\n",
    "    tem  = []\n",
    "    temm = []\n",
    "    tem_token = []\n",
    "    for sen in data:\n",
    "        tokens, positions = parser.tokenize(sen)\n",
    "        tem_token.append(tokens)\n",
    "    \n",
    "    annotations, machines = parser.parse_sentences(tem_token)\n",
    "    tem = annotations\n",
    "    temm = [i.get_amr().to_penman(jamr=False, isi=False) for i in machines]\n",
    "    n = 0\n",
    "    r1 = []\n",
    "    r2 = []\n",
    "    for sen in data:\n",
    "        r1.append(converter.convert(tem[n]))\n",
    "        r2.append(converter.convert(temm[n]))\n",
    "        n+=1\n",
    "    return tem,temm, r1,r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe299178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_substring(s,w1,w2):\n",
    "    p = inflect.engine()\n",
    "#     print(s,w1,w2)\n",
    "    if w1.isnumeric():\n",
    "        w1 = p.number_to_words(w1)\n",
    "    if w2.isnumeric():\n",
    "        w2 = p.number_to_words(w2) \n",
    "    w11 = []\n",
    "    if w1==\"be-located-at\":\n",
    "        w11 = [\"on\",\"at\",\"in\"]\n",
    "    w22 = []\n",
    "    if w2==\"be-located-at\":\n",
    "        w22 = [\"on\",\"at\",\"in\"]\n",
    "    \n",
    "    w111 = []\n",
    "    if w1 == \"person\":\n",
    "        w111 = [str(tok) for tok in nlp(s) if (tok.dep_ == \"nsubj\")]\n",
    "    w222 = []\n",
    "    if w2== \"person\":\n",
    "        w222 = [str(tok) for tok in nlp(s) if (tok.dep_ == \"nsubj\")]\n",
    "\n",
    "\n",
    "    sub1 = [j for i in get_word_forms(w1,0.7) for j in get_word_forms(w1,0.7)[i]]+[w1]+w11+w111\n",
    "    sub2 = [j for i in get_word_forms(w2,0.7) for j in get_word_forms(w2,0.7)[i]]+[w2]+w22+w222\n",
    "    search1 = 0\n",
    "    search2 = 999\n",
    "    c1= 0\n",
    "    c2= 0\n",
    "\n",
    "    token = word_tokenize(s.lower())\n",
    "#     print(token)\n",
    "    for i in range(len(token)):\n",
    "        if token[i] in sub1:\n",
    "            c1 = 1\n",
    "            search1 = i\n",
    "        elif token[i] in sub2:\n",
    "            c2 = 1\n",
    "            search2 = i\n",
    "#     print(search1,search2)\n",
    "# print(search)\n",
    "    if c1 == 0 or c2 == 0:\n",
    "#         rndtem = np.random.randint(len(token),size = 2)\n",
    "         return False\n",
    "\n",
    "    if search1 > search2:\n",
    "#         print(\"The extracted string : \" + \" \".join(token[search2:search1+1]))\n",
    "        return \" \".join(token[search2:search1+1])\n",
    "    else:\n",
    "#         print(\"The extracted string : \" + \" \".join(token[search1:search2+1]))\n",
    "        return \" \".join(token[search1:search2+1])\n",
    "        \n",
    " \n",
    "# printing result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46210d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(final,f = False):\n",
    "    init = True\n",
    "    for i in final:\n",
    "        if type(i) == list:\n",
    "            tem = True\n",
    "            \n",
    "            tem = tem&combine(i)\n",
    "            if ~tem == -1:\n",
    "                \n",
    "                init = init & True\n",
    "            elif ~tem == -2:\n",
    "                if not f:\n",
    "                    init = init & False\n",
    "                else:\n",
    "                    init = init & True\n",
    "            else:\n",
    "                init = init&~tem\n",
    "        else:\n",
    "            init = init&i\n",
    "            \n",
    "    return init\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "188461ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def transform(formula,Var,X):\n",
    "    final = copy.deepcopy(formula)\n",
    "    for i in range(len(final)):\n",
    "        \n",
    "        if type(final[i]) == list:\n",
    "            \n",
    "            if final[i][0] == \"ARG\":\n",
    "                if \" \".join([Var[final[i][1]],Var[final[i][2]],final[i][3]]) not in X:\n",
    "                    continue\n",
    "                else:\n",
    "                    final[i] = X[\" \".join([Var[final[i][1]],Var[final[i][2]],final[i][3]])]\n",
    "#             \n",
    "                \n",
    "#                     init = init\n",
    "            else:\n",
    "                final[i] = transform(final[i],Var,X)\n",
    "               \n",
    "#                     else:\n",
    "                    \n",
    "        else:\n",
    "            if final[i] not in X:\n",
    "                continue\n",
    "        \n",
    "            else:\n",
    "                final[i]  = X[final[i]] \n",
    "  \n",
    "    return final\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e2d24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(formula):\n",
    "    and_list = []\n",
    "    var = {}\n",
    "    arg = []\n",
    "    if type(formula) == types.Not:\n",
    "#         print(\"ggg\")\n",
    "        return [extract(formula.body)[0]],{**extract(formula.body)[1],**var},arg+extract(formula.body)[2]\n",
    "#     print(formula)\n",
    "    for i in formula.args:\n",
    "        if type(i) == types.Not:\n",
    "            and_list.append(extract(i.body)[0])\n",
    "            var = {**extract(i.body)[1],**var}\n",
    "            arg = arg+extract(i.body)[2]\n",
    "           \n",
    "        else:\n",
    "            if i.predicate.symbol[0] ==\":\":\n",
    "#             if i.predicate.symbol[0] ==\"÷:\"\n",
    "                and_list.append([\"ARG\"]+ [i.terms[j].value for j in range(0,len(i.terms))]+[i.predicate.symbol])\n",
    "                arg.append([i.terms[j].value for j in range(0,len(i.terms))]+[i.predicate.symbol])\n",
    "            else:\n",
    "                and_list.append(re.sub(r'\\-*[0-9]',\"\",i.predicate.symbol))\n",
    "                var[i.terms[0].value] = re.sub(r'\\-*[0-9]',\"\",i.predicate.symbol)\n",
    "    return and_list,var,arg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc50f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(s1,s2):\n",
    "    sentences = [s1,s2]\n",
    "    embedding_1= model.encode(sentences[0], convert_to_tensor=True,show_progress_bar=False)\n",
    "    embedding_2 = model.encode(sentences[1], convert_to_tensor=True,show_progress_bar=False)\n",
    "    return util.pytorch_cos_sim(embedding_1, embedding_2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c971903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pysat_formula(formula):\n",
    "    tem_list = []\n",
    "    for i in str(formula).split(\" & \"):\n",
    "        if i[0] == \"x\":\n",
    "            tem_list.append([int(i[1:])])\n",
    "        else:\n",
    "            tem_tem = []\n",
    "            for j in i.replace(\"(\",\"\").replace(\")\",\"\").split(\" | \"):\n",
    "                if j[0] == \"~\":\n",
    "#                 print(int(j[-1]))\n",
    "                    tem_tem.append(int(j[2:])*-1)\n",
    "                elif j[0] == \"x\":\n",
    "                    tem_tem.append(int(j[1:]))\n",
    "            tem_list.append(tem_tem)\n",
    "    return tem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e31eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsitute(x,y,replaceX,replaceXX,maxx,i,j,thre):\n",
    "    tems = score(x,y)\n",
    "                                    \n",
    "    if tems>=thre:\n",
    "        if tems > maxx[i]:\n",
    "            maxx[i] = tems\n",
    "            replaceXX[i] = replaceX[j]\n",
    "            return True\n",
    "    return False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "149dd4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prove(data,sent):\n",
    "    checkArg0 = []\n",
    "    checkVaribale0 = {}\n",
    "    for0,checkVaribale0,checkArg0 = extract(data[0])\n",
    "    for i in checkArg0:\n",
    "        for j in range(len(i)):\n",
    "#             print(j)\n",
    "            if i[j] in checkVaribale0:\n",
    "                i[j] = checkVaribale0[i[j]]\n",
    "            else:\n",
    "                checkVaribale0[i[j]] = i[j]\n",
    "\n",
    "    replaceX = {}\n",
    "    n = 1\n",
    "    for i in checkVaribale0:\n",
    "        if checkVaribale0[i][0] == \":\":\n",
    "            continue\n",
    "        if checkVaribale0[i] not in replaceX:\n",
    "            replaceX[checkVaribale0[i]] = Symbol('x'+str(n))  \n",
    "            n+=1\n",
    "    for i in checkArg0:\n",
    "#         print(i)\n",
    "        if \" \".join(i) not in replaceX:\n",
    "            replaceX[\" \".join(i)] = Symbol('x'+str(n))  \n",
    "            n+=1\n",
    "    explanation = False\n",
    "    if len(data)>2:\n",
    "        explanation = True\n",
    "    if explanation:\n",
    "        checkArg2 = []\n",
    "        checkVaribale2 ={}\n",
    "        for2,checkVaribale2,checkArg2 = extract(data[2])\n",
    "        for i in checkArg2:\n",
    "            for j in range(len(i)):\n",
    "#             print(j)\n",
    "                if i[j] in checkVaribale2:\n",
    "                    i[j] = checkVaribale2[i[j]]\n",
    "                else:\n",
    "                    checkVaribale2[i[j]] = i[j]\n",
    "    \n",
    "#         print(checkVaribale2)\n",
    "        for i in checkVaribale2:\n",
    "#             print(i)\n",
    "            if checkVaribale2[i][0] == \":\":\n",
    "                continue\n",
    "            if checkVaribale2[i] not in replaceX:\n",
    "                replaceX[checkVaribale2[i]] = Symbol('x'+str(n))  \n",
    "                n+=1\n",
    "        for i in checkArg2:\n",
    "            if \" \".join(i) not in replaceX:\n",
    "                replaceX[\" \".join(i)] = Symbol('x'+str(n))  \n",
    "                n+=1\n",
    "    checkArg11 = []\n",
    "    checkVaribale11 ={}\n",
    "    for1,checkVaribale11,checkArg11 = extract(data[1])\n",
    "    \n",
    "    quant = []\n",
    "    for i in checkArg11:\n",
    "        if i[-1][:6]==\":quant\":\n",
    "            try:\n",
    "                quant.append(checkVaribale11[i[1]])\n",
    "            except:\n",
    "                continue\n",
    "    replaceXX = {}\n",
    "\n",
    "    thre = 0.55\n",
    "    for i in checkArg11:\n",
    "        for j in range(len(i)):\n",
    "            if i[j] in checkVaribale11:\n",
    "                i[j] = checkVaribale11[i[j]]\n",
    "            else:\n",
    "#                 else:\n",
    "                checkVaribale11[i[j]] = i[j]\n",
    "    maxx = {}\n",
    "    for i in checkArg11:\n",
    "        maxx[\" \".join(i)] = 0\n",
    "    for i in checkVaribale11:\n",
    "        maxx[checkVaribale11[i]] = 0\n",
    "    temj = \"\"\n",
    "    for i in checkVaribale11:\n",
    "        if checkVaribale11[i] in quant:\n",
    "            replaceXX[checkVaribale11[i]] = True\n",
    "        if checkVaribale11[i][0] == \":\":\n",
    "            continue\n",
    "        if checkVaribale11[i] in replaceX:\n",
    "            replaceXX[checkVaribale11[i]] = replaceX[checkVaribale11[i]]\n",
    "\n",
    "        else:\n",
    "            ccccc = 0\n",
    "            for j in replaceX:\n",
    "                if len(j.split())>1:\n",
    "                    continue\n",
    "\n",
    "                subsitute(checkVaribale11[i],j,replaceX,replaceXX,maxx,checkVaribale11[i],j,thre)\n",
    "                \n",
    "            if maxx[checkVaribale11[i]] == 0:\n",
    "                replaceXX[checkVaribale11[i]] =Symbol('x'+str(n))\n",
    "#                 formula11 = &formula11\n",
    "                \n",
    "                n+=1\n",
    "    for i in checkArg11:\n",
    "        if \" \".join(i) in replaceXX:\n",
    "            continue\n",
    "#         print(i)\n",
    "        if \" \".join(i) in replaceX:\n",
    "#             print(i)\n",
    "            replaceXX[\" \".join(i)] = replaceX[\" \".join(i)]\n",
    "\n",
    "        else:\n",
    "            temj = \" \"\n",
    "            for j in replaceX:\n",
    "                \n",
    "#                 print(j)\n",
    "                if len(j.split())<3:\n",
    "#                     continue\n",
    "                    if True:\n",
    "#                         print(j,i,temj)\n",
    "                        \n",
    "                        if subsitute(j,\" \".join([i[0],i[-2]]),replaceX,replaceXX,maxx,\" \".join(i),j,thre):\n",
    "                            temj = j\n",
    "                               \n",
    "                \n",
    "                else:\n",
    "\n",
    "                            tems3 = False\n",
    "                            tems1 = get_substring(sent[1],i[0],i[-2])\n",
    "                            tems2 = get_substring(sent[0],j.split()[0],j.split()[-2])\n",
    "                            if explanation:\n",
    "                                tems3 = get_substring(sent[2],j.split()[0],j.split()[-2])\n",
    "#                            \n",
    "                            if not tems1:\n",
    "                                if tems2:\n",
    "                                    if subsitute(\" \".join([i[0],i[-2]]),tems2,replaceX,replaceXX,maxx,\" \".join(i),j,thre,):\n",
    "                                        temj = j\n",
    "    \n",
    "                                if tems3:\n",
    "                                    if subsitute(\" \".join([i[0],i[-2]]),tems3,replaceX,replaceXX,maxx,\" \".join(i),j,thre):\n",
    "                                        temj = j\n",
    "                                   \n",
    "                                if subsitute(\" \".join([i[0],i[-2]]),\" \".join([j.split()[0],j.split()[1]]),replaceX,replaceXX,maxx,\" \".join(i),j,thre,):\n",
    "                                    temj = j\n",
    "                           \n",
    "                                        \n",
    "                            if tems2 and tems1:\n",
    "                                if subsitute(tems1,tems2,replaceX,replaceXX,maxx,\" \".join(i),j,thre,):\n",
    "                                    temj = j\n",
    "                                \n",
    "                        \n",
    "                            if tems3 and tems1:\n",
    "                                if subsitute(tems1,tems3,replaceX,replaceXX,maxx,\" \".join(i),j,thre,):\n",
    "                                    temj = j\n",
    "                   \n",
    "            if maxx[\" \".join(i)] == 0:\n",
    "                replaceXX[\" \".join(i)] = Symbol('x'+str(n))\n",
    "                n+=1\n",
    "            else:\n",
    "#                 print(temj, i,maxx[\" \".join(i)])\n",
    "               \n",
    "                if i[0] in replaceXX:\n",
    "                    replaceXX[i[0]] = True\n",
    "                if i[-2] in replaceXX:\n",
    "                    replaceXX[i[-2]]= True\n",
    "    new_rex = {}\n",
    "    for i in replaceXX:\n",
    "        if i == \"and\":\n",
    "            new_rex[i] = True\n",
    "        if i.split()[0]==\"and\" and i.split()[-1][:3]==\":op\":\n",
    "            new_rex[i] = new_rex[i.split()[1]]\n",
    "        else:\n",
    "            new_rex[i] = replaceXX[i]\n",
    "    new_re = {}\n",
    "#     print(for2)\n",
    "    for i in replaceX:\n",
    "#         print(replaceXX.values())\n",
    "        tcc = 0\n",
    "        for j in new_rex:\n",
    "        \n",
    "            if isinstance(new_rex[j], sympy.Not):\n",
    "                if ~new_rex[j] == replaceX[i]:\n",
    "#                     print(new_rex[j] ,~new_rex[j] )\n",
    "                    new_re[i] = replaceX[i]\n",
    "                    tcc = 1\n",
    "            else:\n",
    "                if new_rex[j] == replaceX[i]:\n",
    "                    new_re[i] = replaceX[i]\n",
    "                    tcc = 1\n",
    "        if tcc == 0:\n",
    "                new_re[i] = True\n",
    "\n",
    "    formula0 = combine(transform(for0,checkVaribale0, replaceX))\n",
    "\n",
    "    formula11 =  combine(transform(for1,checkVaribale11, new_rex))\n",
    "#     return 0\n",
    "    if formula11 == -1:\n",
    "        formula11 = True\n",
    "    elif formula11 == -2:\n",
    "        formula11 =False\n",
    "    elif formula11 == 0:\n",
    "        formula11 =False\n",
    "    elif formula11 == 1:\n",
    "        formula11 =True\n",
    "    if explanation:\n",
    "        formula2 = combine(transform(for2,checkVaribale2, replaceX))\n",
    "        final_formula = to_cnf( (formula0 & formula2 ) & ~(formula11))\n",
    "    else:\n",
    "        final_formula = to_cnf( formula0 & ~(formula11))\n",
    "    cnf = CNF(from_clauses=pysat_formula(final_formula))\n",
    "   \n",
    "    formula00 = combine(transform(for0,checkVaribale0, new_re))\n",
    "    \n",
    "    if explanation:\n",
    "        formula22 = combine(transform(for2,checkVaribale2, new_re))\n",
    "        if formula22 == -1:\n",
    "            formula22 = True\n",
    "        elif formula22 == -2:\n",
    "            formula22 = False\n",
    "        elif formula22 == 1:\n",
    "            formula22 = True\n",
    "        elif formula22 == 0:\n",
    "            formula22 = False\n",
    "        if formula00 == -1:\n",
    "            formula00 = True\n",
    "        elif formula00 == -2:\n",
    "            formula00 =False\n",
    "        elif formula00 == 1:\n",
    "            formula00 =True\n",
    "        elif formula00 == 0:\n",
    "            formula00 =False\n",
    "        final_formula11 = to_cnf( formula00 & formula22 & formula11)\n",
    "    else:\n",
    "        if formula00 == -1:\n",
    "            formula00 = True\n",
    "        elif formula00 == -2:\n",
    "            fomula00 = False\n",
    "\n",
    "        final_formula11 = to_cnf( formula00 & formula11)\n",
    "\n",
    "    cnf11 = CNF(from_clauses=pysat_formula(final_formula11))\n",
    "#\n",
    "    with Solver(name = \"Minisat22\",bootstrap_with=cnf) as solver:\n",
    "        \n",
    "        check_ent = solver.solve()\n",
    "\n",
    "    with Solver(name = \"Minisat22\",bootstrap_with=cnf11) as solver:\n",
    "        check_con1 = solver.solve()\n",
    "#     print(check_con)\n",
    "    if not check_ent and check_con1:\n",
    "        return \"ent\"\n",
    "    elif not check_con1 and check_ent:\n",
    "\n",
    "        return \"con\"\n",
    "    \n",
    "    elif not check_con1 and not check_ent:\n",
    "        return \"both\"\n",
    "\n",
    "    else:\n",
    "        return \"neu\"\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a2154aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb746241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('esnli_train_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e49781f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sent_ent = []\n",
    "sent_con = []\n",
    "sent_neu = []\n",
    "length = 2999999\n",
    "for i in range(0,259999):\n",
    "\n",
    "        try:\n",
    "            if len(word_tokenize(df.iloc[i,2]))>length or len(word_tokenize(df.iloc[i,3]))>length or len(word_tokenize(df.iloc[i,4]))>length:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if df.iloc[i,1] == \"entailment\":\n",
    "#             conti\n",
    "\n",
    "            sent_ent.append([df.iloc[i,2],df.iloc[i,3],df.iloc[i,4],'ent'])\n",
    "\n",
    "        elif df.iloc[i,1] == \"contradiction\":\n",
    "            sent_con.append([df.iloc[i,2],df.iloc[i,3],df.iloc[i,4],'con'])   \n",
    "        else:\n",
    "#             elif df.iloc[i,1] == \"contradicton\":\n",
    "            sent_neu.append([df.iloc[i,2],df.iloc[i,3],df.iloc[i,4],'neu']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "215bfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "esnli_sent = [sent_ent[i] for i in np.random.choice(len(sent_ent), 50\n",
    "                                                    ,replace=False)]+[sent_neu[i] for i in np.random.choice(len(sent_neu), 50,replace=False)]+[sent_con[i] for i in np.random.choice(len(sent_con), 50,replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04af7923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(esnli_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cd9851d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1029: UserWarning: An output with one or more elements was resized since it had shape [3, 2], which does not match the required output shape [2, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.add(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1040: UserWarning: An output with one or more elements was resized since it had shape [3, 1], which does not match the required output shape [2, 1]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.topk(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1070: UserWarning: An output with one or more elements was resized since it had shape [3, 1], which does not match the required output shape [2, 1]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.gather(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:937: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.masked_select(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1029: UserWarning: An output with one or more elements was resized since it had shape [2, 2], which does not match the required output shape [1, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.add(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1040: UserWarning: An output with one or more elements was resized since it had shape [2, 1], which does not match the required output shape [1, 1]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.topk(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1070: UserWarning: An output with one or more elements was resized since it had shape [2, 1], which does not match the required output shape [1, 1]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.gather(\n",
      "\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.69s/it]\u001b[A\n",
      "  1%|▎                                          | 1/150 [00:02<06:43,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.68s/it]\u001b[A\n",
      "  1%|▌                                          | 2/150 [00:06<08:06,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.67s/it]\u001b[A\n",
      "  2%|▊                                          | 3/150 [00:08<06:15,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.00s/it]\u001b[A\n",
      "  3%|█▏                                         | 4/150 [00:11<06:38,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:07<00:00,  7.31s/it]\u001b[A\n",
      "  3%|█▍                                         | 5/150 [00:18<10:35,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.41s/it]\u001b[A\n",
      "  4%|█▋                                         | 6/150 [00:20<08:55,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.37s/it]\u001b[A\n",
      "  5%|██                                         | 7/150 [00:23<07:48,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.44s/it]\u001b[A\n",
      "  5%|██▎                                        | 8/150 [00:25<07:07,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.86s/it]\u001b[A\n",
      "  6%|██▌                                        | 9/150 [00:29<07:42,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:07<00:00,  7.63s/it]\u001b[A\n",
      "  7%|██▊                                       | 10/150 [00:37<10:47,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING: disconnected graphs\u001b[0m\n",
      "\u001b[93mWARNING: disconnected graphs\u001b[0m\n",
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\u001b[A\n",
      "  7%|███                                       | 11/150 [00:39<08:46,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.30s/it]\u001b[A\n",
      "  8%|███▎                                      | 12/150 [00:41<07:40,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.36s/it]\u001b[A\n",
      "  9%|███▋                                      | 13/150 [00:45<08:19,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.64s/it]\u001b[A\n",
      "  9%|███▉                                      | 14/150 [00:47<06:53,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.31s/it]\u001b[A\n",
      " 10%|████▏                                     | 15/150 [00:50<07:01,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1029: UserWarning: An output with one or more elements was resized since it had shape [3, 2], which does not match the required output shape [1, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.add(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1040: UserWarning: An output with one or more elements was resized since it had shape [3, 1], which does not match the required output shape [1, 1]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.topk(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1070: UserWarning: An output with one or more elements was resized since it had shape [3, 1], which does not match the required output shape [1, 1]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.gather(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:937: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.masked_select(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:943: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.masked_select(\n",
      "\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.91s/it]\u001b[A\n",
      " 11%|████▍                                     | 16/150 [00:53<06:50,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.75s/it]\u001b[A\n",
      " 11%|████▊                                     | 17/150 [00:56<06:35,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.10s/it]\u001b[A\n",
      " 12%|█████                                     | 18/150 [00:59<06:37,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.50s/it]\u001b[A\n",
      " 13%|█████▎                                    | 19/150 [01:00<05:35,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.70s/it]\u001b[A\n",
      " 13%|█████▌                                    | 20/150 [01:03<05:38,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.21s/it]\u001b[A\n",
      " 14%|█████▉                                    | 21/150 [01:06<05:59,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.72s/it]\u001b[A\n",
      " 15%|██████▏                                   | 22/150 [01:09<05:54,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.84s/it]\u001b[A\n",
      " 15%|██████▍                                   | 23/150 [01:11<05:16,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.00s/it]\u001b[A\n",
      " 16%|██████▋                                   | 24/150 [01:13<04:55,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.28s/it]\u001b[A\n",
      " 17%|███████                                   | 25/150 [01:15<04:50,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.96s/it]\u001b[A\n",
      " 17%|███████▎                                  | 26/150 [01:18<05:12,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.86s/it]\u001b[A\n",
      " 18%|███████▌                                  | 27/150 [01:21<05:22,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.77s/it]\u001b[A\n",
      " 19%|███████▊                                  | 28/150 [01:23<04:48,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.36s/it]\u001b[A\n",
      " 19%|████████                                  | 29/150 [01:25<04:46,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.56s/it]\u001b[A\n",
      " 20%|████████▍                                 | 30/150 [01:28<04:50,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 21%|████████▋                                 | 31/150 [01:30<04:39,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.18s/it]\u001b[A\n",
      " 21%|████████▉                                 | 32/150 [01:32<04:31,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.18s/it]\u001b[A\n",
      " 22%|█████████▏                                | 33/150 [01:34<04:25,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.07s/it]\u001b[A\n",
      " 23%|█████████▌                                | 34/150 [01:36<04:16,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.14s/it]\u001b[A\n",
      " 23%|█████████▊                                | 35/150 [01:39<04:12,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\u001b[A\n",
      " 24%|██████████                                | 36/150 [01:40<03:59,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.09s/it]\u001b[A\n",
      " 25%|██████████▎                               | 37/150 [01:42<03:57,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.07s/it]\u001b[A\n",
      " 25%|██████████▋                               | 38/150 [01:45<03:54,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.74s/it]\u001b[A\n",
      " 26%|██████████▉                               | 39/150 [01:46<03:40,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.23s/it]\u001b[A\n",
      " 27%|███████████▏                              | 40/150 [01:49<03:46,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.23s/it]\u001b[A\n",
      " 27%|███████████▍                              | 41/150 [01:51<03:50,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.02s/it]\u001b[A\n",
      " 28%|███████████▊                              | 42/150 [01:54<04:17,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.83s/it]\u001b[A\n",
      " 29%|████████████                              | 43/150 [01:58<05:01,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.11s/it]\u001b[A\n",
      " 29%|████████████▎                             | 44/150 [02:01<05:08,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.34s/it]\u001b[A\n",
      " 30%|████████████▌                             | 45/150 [02:04<05:19,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.46s/it]\u001b[A\n",
      " 31%|████████████▉                             | 46/150 [02:06<04:27,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.85s/it]\u001b[A\n",
      " 31%|█████████████▏                            | 47/150 [02:08<04:33,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:943: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.masked_select(\n",
      "\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.11s/it]\u001b[A\n",
      " 32%|█████████████▍                            | 48/150 [02:12<04:44,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.21s/it]\u001b[A\n",
      " 33%|█████████████▋                            | 49/150 [02:15<04:54,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.62s/it]\u001b[A\n",
      " 33%|██████████████                            | 50/150 [02:17<04:43,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.39s/it]\u001b[A\n",
      " 34%|██████████████▎                           | 51/150 [02:22<05:26,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.89s/it]\u001b[A\n",
      " 35%|██████████████▌                           | 52/150 [02:25<05:11,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.32s/it]\u001b[A\n",
      " 35%|██████████████▊                           | 53/150 [02:29<05:41,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.27s/it]\u001b[A\n",
      " 36%|███████████████                           | 54/150 [02:33<06:00,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n",
      " 37%|███████████████▍                          | 55/150 [02:35<05:06,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 37%|███████████████▋                          | 56/150 [02:39<05:09,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.01s/it]\u001b[A\n",
      " 38%|███████████████▉                          | 57/150 [02:43<05:26,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:06<00:00,  6.04s/it]\u001b[A\n",
      " 39%|████████████████▏                         | 58/150 [02:49<06:33,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.48s/it]\u001b[A\n",
      " 39%|████████████████▌                         | 59/150 [02:51<05:40,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.91s/it]\u001b[A\n",
      " 40%|████████████████▊                         | 60/150 [02:54<05:14,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.52s/it]\u001b[A\n",
      " 41%|█████████████████                         | 61/150 [02:58<05:11,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.41s/it]\u001b[A\n",
      " 41%|█████████████████▎                        | 62/150 [03:00<04:39,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 42%|█████████████████▋                        | 63/150 [03:02<04:08,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.63s/it]\u001b[A\n",
      " 43%|█████████████████▉                        | 64/150 [03:07<04:51,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.72s/it]\u001b[A\n",
      " 43%|██████████████████▏                       | 65/150 [03:11<04:56,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.02s/it]\u001b[A\n",
      " 44%|██████████████████▍                       | 66/150 [03:14<04:41,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.68s/it]\u001b[A\n",
      " 45%|██████████████████▊                       | 67/150 [03:17<04:46,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.40s/it]\u001b[A\n",
      " 45%|███████████████████                       | 68/150 [03:22<05:06,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.78s/it]\u001b[A\n",
      " 46%|███████████████████▎                      | 69/150 [03:25<04:39,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.72s/it]\u001b[A\n",
      " 47%|███████████████████▌                      | 70/150 [03:27<04:18,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.30s/it]\u001b[A\n",
      " 47%|███████████████████▉                      | 71/150 [03:30<03:53,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.11s/it]\u001b[A\n",
      " 48%|████████████████████▏                     | 72/150 [03:33<03:54,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.48s/it]\u001b[A\n",
      " 49%|████████████████████▍                     | 73/150 [03:35<03:39,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.79s/it]\u001b[A\n",
      " 49%|████████████████████▋                     | 74/150 [03:38<03:35,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\u001b[A\n",
      " 50%|█████████████████████                     | 75/150 [03:40<03:10,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.50s/it]\u001b[A\n",
      " 51%|█████████████████████▎                    | 76/150 [03:42<03:07,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.22s/it]\u001b[A\n",
      " 51%|█████████████████████▌                    | 77/150 [03:45<02:57,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.95s/it]\u001b[A\n",
      " 52%|█████████████████████▊                    | 78/150 [03:47<03:06,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.90s/it]\u001b[A\n",
      " 53%|██████████████████████                    | 79/150 [03:50<03:10,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.00s/it]\u001b[A\n",
      " 53%|██████████████████████▍                   | 80/150 [03:53<03:14,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.75s/it]\u001b[A\n",
      " 54%|██████████████████████▋                   | 81/150 [03:57<03:32,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.56s/it]\u001b[A\n",
      " 55%|██████████████████████▉                   | 82/150 [04:01<03:39,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.81s/it]\u001b[A\n",
      " 55%|███████████████████████▏                  | 83/150 [04:04<03:27,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.85s/it]\u001b[A\n",
      " 56%|███████████████████████▌                  | 84/150 [04:06<03:19,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.39s/it]\u001b[A\n",
      " 57%|███████████████████████▊                  | 85/150 [04:11<03:43,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.60s/it]\u001b[A\n",
      " 57%|████████████████████████                  | 86/150 [04:12<03:04,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.26s/it]\u001b[A\n",
      " 58%|████████████████████████▎                 | 87/150 [04:16<03:09,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.81s/it]\u001b[A\n",
      " 59%|████████████████████████▋                 | 88/150 [04:21<03:39,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.65s/it]\u001b[A\n",
      " 59%|████████████████████████▉                 | 89/150 [04:24<03:38,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.70s/it]\u001b[A\n",
      " 60%|█████████████████████████▏                | 90/150 [04:27<03:19,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:06<00:00,  6.16s/it]\u001b[A\n",
      " 61%|█████████████████████████▍                | 91/150 [04:33<04:06,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING: disconnected graphs\u001b[0m\n",
      "\u001b[93mWARNING: disconnected graphs\u001b[0m\n",
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.30s/it]\u001b[A\n",
      " 61%|█████████████████████████▊                | 92/150 [04:36<03:46,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.86s/it]\u001b[A\n",
      " 62%|██████████████████████████                | 93/150 [04:39<03:25,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING: disconnected graphs\u001b[0m\n",
      "\u001b[93mWARNING: disconnected graphs\u001b[0m\n",
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.86s/it]\u001b[A\n",
      " 63%|██████████████████████████▎               | 94/150 [04:42<03:09,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.56s/it]\u001b[A\n",
      " 63%|██████████████████████████▌               | 95/150 [04:45<02:52,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.61s/it]\u001b[A\n",
      " 64%|██████████████████████████▉               | 96/150 [04:47<02:40,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.82s/it]\u001b[A\n",
      " 65%|███████████████████████████▏              | 97/150 [04:51<02:51,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.43s/it]\u001b[A\n",
      " 65%|███████████████████████████▍              | 98/150 [04:55<03:06,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.37s/it]\u001b[A\n",
      " 66%|███████████████████████████▋              | 99/150 [04:59<02:59,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.49s/it]\u001b[A\n",
      " 67%|███████████████████████████▎             | 100/150 [05:01<02:40,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.27s/it]\u001b[A\n",
      " 67%|███████████████████████████▌             | 101/150 [05:04<02:23,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.59s/it]\u001b[A\n",
      " 68%|███████████████████████████▉             | 102/150 [05:08<02:44,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.79s/it]\u001b[A\n",
      " 69%|████████████████████████████▏            | 103/150 [05:11<02:32,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.35s/it]\u001b[A\n",
      " 69%|████████████████████████████▍            | 104/150 [05:13<02:16,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.57s/it]\u001b[A\n",
      " 70%|████████████████████████████▋            | 105/150 [05:18<02:35,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 71%|████████████████████████████▉            | 106/150 [05:20<02:14,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n",
      " 71%|█████████████████████████████▏           | 107/150 [05:22<01:57,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.52s/it]\u001b[A\n",
      " 72%|█████████████████████████████▌           | 108/150 [05:25<01:52,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.86s/it]\u001b[A\n",
      " 73%|█████████████████████████████▊           | 109/150 [05:27<01:51,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.46s/it]\u001b[A\n",
      " 73%|██████████████████████████████           | 110/150 [05:32<02:09,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.31s/it]\u001b[A\n",
      " 74%|██████████████████████████████▎          | 111/150 [05:35<02:07,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.66s/it]\u001b[A\n",
      " 75%|██████████████████████████████▌          | 112/150 [05:38<01:57,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.24s/it]\u001b[A\n",
      " 75%|██████████████████████████████▉          | 113/150 [05:40<01:44,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.22s/it]\u001b[A\n",
      " 76%|███████████████████████████████▏         | 114/150 [05:42<01:35,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.95s/it]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 115/150 [05:46<01:46,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.14s/it]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 116/150 [05:50<01:54,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\u001b[A\n",
      " 78%|███████████████████████████████▉         | 117/150 [05:53<01:38,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.75s/it]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 118/150 [05:57<01:52,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.70s/it]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 119/150 [06:00<01:41,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.94s/it]\u001b[A\n",
      " 80%|████████████████████████████████▊        | 120/150 [06:03<01:35,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 81%|█████████████████████████████████        | 121/150 [06:05<01:23,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.62s/it]\u001b[A\n",
      " 81%|█████████████████████████████████▎       | 122/150 [06:08<01:18,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:05<00:00,  5.34s/it]\u001b[A\n",
      " 82%|█████████████████████████████████▌       | 123/150 [06:13<01:36,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      " 83%|█████████████████████████████████▉       | 124/150 [06:17<01:31,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.23s/it]\u001b[A\n",
      " 83%|██████████████████████████████████▏      | 125/150 [06:20<01:25,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.63s/it]\u001b[A\n",
      " 84%|██████████████████████████████████▍      | 126/150 [06:21<01:09,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.14s/it]\u001b[A\n",
      " 85%|██████████████████████████████████▋      | 127/150 [06:25<01:08,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.87s/it]\u001b[A\n",
      " 85%|██████████████████████████████████▉      | 128/150 [06:26<00:58,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.75s/it]\u001b[A\n",
      " 86%|███████████████████████████████████▎     | 129/150 [06:29<00:56,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.28s/it]\u001b[A\n",
      " 87%|███████████████████████████████████▌     | 130/150 [06:31<00:51,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.05s/it]\u001b[A\n",
      " 87%|███████████████████████████████████▊     | 131/150 [06:34<00:45,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.02s/it]\u001b[A\n",
      " 88%|████████████████████████████████████     | 132/150 [06:38<00:52,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.66s/it]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 133/150 [06:39<00:42,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.66s/it]\u001b[A\n",
      " 89%|████████████████████████████████████▋    | 134/150 [06:43<00:45,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 135/150 [06:45<00:39,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.67s/it]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 136/150 [06:49<00:41,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.56s/it]\u001b[A\n",
      " 91%|█████████████████████████████████████▍   | 137/150 [06:51<00:36,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.03s/it]\u001b[A\n",
      " 92%|█████████████████████████████████████▋   | 138/150 [06:54<00:34,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.91s/it]\u001b[A\n",
      " 93%|█████████████████████████████████████▉   | 139/150 [06:57<00:31,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.99s/it]\u001b[A\n",
      " 93%|██████████████████████████████████████▎  | 140/150 [07:00<00:29,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.23s/it]\u001b[A\n",
      " 94%|██████████████████████████████████████▌  | 141/150 [07:03<00:27,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 95%|██████████████████████████████████████▊  | 142/150 [07:06<00:22,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.51s/it]\u001b[A\n",
      " 95%|███████████████████████████████████████  | 143/150 [07:10<00:22,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.32s/it]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 144/150 [07:12<00:17,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.61s/it]\u001b[A\n",
      " 97%|███████████████████████████████████████▋ | 145/150 [07:15<00:14,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.62s/it]\u001b[A\n",
      " 97%|███████████████████████████████████████▉ | 146/150 [07:18<00:11,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.53s/it]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 147/150 [07:20<00:08,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.95s/it]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 148/150 [07:23<00:05,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:04<00:00,  4.48s/it]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 149/150 [07:28<00:03,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.91s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████| 150/150 [07:31<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "pre_data = []\n",
    "for i in tqdm(esnli_sent):\n",
    "#     try:\n",
    "    pre_data.append(generate_logic(i[:-1])[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47b32465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████▏                              | 40/150 [00:35<01:56,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████                         | 61/150 [01:36<05:05,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████▊                       | 67/150 [01:51<03:35,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|███████████████████▌                      | 70/150 [01:54<02:09,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████▋                     | 74/150 [02:03<02:38,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████▎                    | 76/150 [02:05<01:58,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████████████████████▌                    | 77/150 [02:06<01:54,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████                  | 86/150 [02:27<02:20,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████                | 93/150 [02:45<02:45,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████████████▋              | 99/150 [03:00<02:27,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████▌             | 101/150 [03:01<01:31,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████▊        | 120/150 [03:40<00:50,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████▎ | 144/150 [04:13<00:11,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 150/150 [04:22<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "ll = []\n",
    "gl = []\n",
    "for i in tqdm(range(0,150)):\n",
    "    try:\n",
    "#     pre_data = (generate_logic(i[:-1])[-2])\n",
    "        tem = prove(pre_data[i][:],esnli_sent[i])\n",
    "#         print(tem)\n",
    "        if tem == \"both\":\n",
    "            print(\"both\")\n",
    "            continue\n",
    "        ll.append(tem)\n",
    "        gl.append(esnli_sent[i][-1])\n",
    "    except:\n",
    "        print(\"exception\")\n",
    "        continue\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fa7bccc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.591241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         con       0.47      0.70      0.56        47\n",
      "         ent       0.75      0.94      0.84        49\n",
      "         neu       0.33      0.05      0.09        41\n",
      "\n",
      "    accuracy                           0.59       137\n",
      "   macro avg       0.52      0.56      0.50       137\n",
      "weighted avg       0.53      0.59      0.52       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testy = gl\n",
    "yhat_classes = ll\n",
    "\n",
    "accuracy = accuracy_score(testy, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(testy, yhat_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "145633c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46,  1,  2],\n",
       "       [12, 33,  2],\n",
       "       [ 3, 36,  2]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(testy, yhat_classes,labels = [\"ent\",\"con\",\"neu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7876ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = [load_dataset(\"sick\",split=\"train\"),load_dataset(\"sick\",split=\"test\"),load_dataset(\"sick\",split=\"validation\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02e65096",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_ent = []\n",
    "sent_con = []\n",
    "sent_neu = []\n",
    "length = 10\n",
    "# with open('sentences.txt', 'w') as f:\n",
    "for j in dataset:\n",
    "    for i in j:\n",
    "#         print(i)÷\n",
    "#         if df.iloc[i,1] != \"entailment\":\n",
    "#             continue\n",
    "        if len(word_tokenize(i[\"sentence_A\"]))>length or len(word_tokenize(i[\"sentence_A\"]))>length:\n",
    "            continue\n",
    "#         print(df.iloc[i,3])\n",
    "        \n",
    "#         print(generated_sentence)\n",
    "        if i[\"label\"] == 0:\n",
    "            if i[\"entailment_AB\"] == ' A_entails_B':\n",
    "#             conti\n",
    "                sent_ent.append([i[\"sentence_A\"],i[\"sentence_B\"],'ent'])\n",
    "            else:\n",
    "                sent_ent.append([i[\"sentence_B\"],i[\"sentence_A\"],'ent'])\n",
    "        elif i[\"label\"] == 1:\n",
    "            if i[\"entailment_AB\"] == ' A_neutral_B':\n",
    "#             conti\n",
    "                sent_neu.append([i[\"sentence_A\"],i[\"sentence_B\"],'neu'])\n",
    "            else:\n",
    "                sent_neu.append([i[\"sentence_B\"],i[\"sentence_A\"],'neu'])\n",
    "\n",
    "        elif i[\"label\"] == 2:\n",
    "            if i[\"entailment_AB\"] == ' A_contradicts_B':\n",
    "#             conti\n",
    "                sent_con.append([i[\"sentence_A\"],i[\"sentence_B\"],'con'])\n",
    "            else:\n",
    "                sent_con.append([i[\"sentence_B\"],i[\"sentence_A\"],'con'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "177bbe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sick_sent = [sent_ent[i] for i in np.random.choice(len(sent_ent)\n",
    "                                                   , 10,replace=False)]+[sent_neu[i] for i in np\n",
    "    .random.choice(len(sent_neu), 10,replace=False)]+[sent_con[i] for i in np.random.choice(len(sent_con),10,replace = False)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03bd271d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.55s/it]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:01<00:45,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.75s/it]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:03<00:57,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.32s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:05<00:49,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1029: UserWarning: An output with one or more elements was resized since it had shape [2, 2], which does not match the required output shape [1, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.add(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1040: UserWarning: An output with one or more elements was resized since it had shape [2, 1], which does not match the required output shape [1, 1]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.topk(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1070: UserWarning: An output with one or more elements was resized since it had shape [2, 1], which does not match the required output shape [1, 1]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.gather(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:937: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.masked_select(\n",
      "\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.12s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:07<00:50,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.58s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:09<00:50,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:12<00:51,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.52s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:14<00:48,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.32s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:15<00:42,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.62s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:17<00:40,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.74s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:19<00:40,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.24s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:21<00:35,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.81s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:24<00:37,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:25<00:34,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.21s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:27<00:30,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:29<00:30,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:31<00:24,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.19s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:32<00:22,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.16s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:34<00:19,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.78s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:36<00:21,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.24s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:38<00:18,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.66s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:40<00:18,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:42<00:16,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.25s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:44<00:12,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.24s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:45<00:09,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.48s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:47<00:08,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.48s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:48<00:06,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.78s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:50<00:05,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:52<00:03,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.31s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:54<00:01,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.39s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:55<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "ll_sick = []\n",
    "gl_sick = []\n",
    "for i in tqdm(sick_sent):\n",
    "    try:\n",
    "        pre_data = (generate_logic(i[:-1])[-2])\n",
    "        tem = prove(pre_data,i)\n",
    "#         print(tem)\n",
    "        if tem == \"both\":\n",
    "            print(\"both\")\n",
    "            continue\n",
    "        ll_sick.append(tem)\n",
    "        gl_sick.append(i[-1])\n",
    "    except:\n",
    "        print(\"exception\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8db5d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.700000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         con       0.67      0.80      0.73        10\n",
      "         ent       0.67      1.00      0.80        10\n",
      "         neu       1.00      0.30      0.46        10\n",
      "\n",
      "    accuracy                           0.70        30\n",
      "   macro avg       0.78      0.70      0.66        30\n",
      "weighted avg       0.78      0.70      0.66        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testy = gl_sick\n",
    "yhat_classes = ll_sick\n",
    "\n",
    "accuracy = accuracy_score(testy, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(testy, yhat_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e95401",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_sick\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fdd9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_mnli = []\n",
    "with open('multinli_1.0_train.jsonl') as f:\n",
    "    for line in f:\n",
    "        data_mnli.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd9104b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_ent = []\n",
    "sent_con = []\n",
    "sent_neu = []\n",
    "length = 10\n",
    "# with open('sentences.txt', 'w') as f:\n",
    "for i in data_mnli:\n",
    "#         if df.iloc[i,1] != \"entailment\":\n",
    "#             continue\n",
    "        if len(word_tokenize(i[\"sentence1\"]))>length or len(word_tokenize(i[\"sentence2\"]))>length:\n",
    "            continue\n",
    "#         print(df.iloc[i,3])\n",
    "        \n",
    "#         print(generated_sentence)\n",
    "        if i[\"gold_label\"] == \"entailment\":\n",
    "#             conti\n",
    "            sent_ent.append([i[\"sentence1\"],i[\"sentence2\"],'ent'])\n",
    "\n",
    "        elif i[\"gold_label\"] == \"contradiction\":\n",
    "            sent_con.append([i[\"sentence1\"],i[\"sentence2\"],'con'])   \n",
    "        else:\n",
    "#             elif df.iloc[i,1] == \"contradicton\":\n",
    "            sent_neu.append([i[\"sentence1\"],i[\"sentence2\"],'neu']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e915d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_sent = [sent_ent[i] for i in np.random.choice(len(sent_ent)\n",
    "                                ,10,replace=False)]+[sent_neu[i] for i in np.random.choice(len(sent_neu), 10\n",
    "                                                    ,replace=False)]+[sent_con[i] for i in np.random.choice(len(sent_con), 10\n",
    "                                                    ,replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf060d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1029: UserWarning: An output with one or more elements was resized since it had shape [2, 2], which does not match the required output shape [1, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.add(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1040: UserWarning: An output with one or more elements was resized since it had shape [2, 1], which does not match the required output shape [1, 1]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.topk(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:1070: UserWarning: An output with one or more elements was resized since it had shape [2, 1], which does not match the required output shape [1, 1]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.gather(\n",
      "/Users/xuyaofeng/Downloads/transition-amr-parser-master/src/fairseq_ext/sequence_generator_bartsv.py:937: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Resize.cpp:24.)\n",
      "  torch.masked_select(\n",
      "\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.83s/it]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:03<01:27,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  1.70it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:03<00:44,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.35s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:07<01:08,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.36s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:09<00:59,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.49s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:12<01:02,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.42s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:13<00:53,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:15<00:49,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.28s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:19<00:57,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:22<00:57,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.44s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:24<00:50,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.19s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:26<00:42,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.22s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:29<00:46,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.18s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:34<00:55,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.61s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:36<00:48,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.52s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:39<00:42,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.73s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:41<00:38,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.54s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:44<00:36,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.82s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:47<00:32,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.55s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:49<00:29,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:51<00:24,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.15s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:53<00:19,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.67s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:55<00:18,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.31s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:57<00:15,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.63s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:00<00:14,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:04<00:14,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.37s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:07<00:11,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:08<00:07,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.89s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:12<00:05,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:02<00:00,  2.28s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:15<00:02,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "decoding:   0%|                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "decoding: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [01:17<00:00,  2.57s/it]\n"
     ]
    }
   ],
   "source": [
    "ll_mn = []\n",
    "gl_mn = []\n",
    "for i in tqdm(mnli_sent):\n",
    "    try:\n",
    "        pre_data = (generate_logic(i[:-1])[-2])\n",
    "        tem = prove(pre_data,i)\n",
    "#         print(tem)\n",
    "        if tem == \"both\":\n",
    "            print(\"both\")\n",
    "            continue\n",
    "        ll_mn.append(tem)\n",
    "        gl_mn.append(i[-1])\n",
    "    except:\n",
    "        print(\"exception\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e49c29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.500000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         con       1.00      0.30      0.46        10\n",
      "         ent       0.50      0.70      0.58        10\n",
      "         neu       0.38      0.50      0.43        10\n",
      "\n",
      "    accuracy                           0.50        30\n",
      "   macro avg       0.63      0.50      0.49        30\n",
      "weighted avg       0.63      0.50      0.49        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testy = gl_mn\n",
    "yhat_classes = ll_mn\n",
    "\n",
    "accuracy = accuracy_score(testy, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(testy, yhat_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9bc47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
